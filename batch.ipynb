{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-0.19.1-py2.py3-none-any.whl (17 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-0.19.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ndjson in /Users/yottan/.pyenv/versions/anaconda3-2020.07/envs/streamlit-custom/lib/python3.8/site-packages (0.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ndjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting demoji\n",
      "  Using cached demoji-1.1.0-py3-none-any.whl (42 kB)\n",
      "Installing collected packages: demoji\n",
      "Successfully installed demoji-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c258806e9f33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msentence_vectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mdotenv_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.env'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mload_dotenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdotenv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import smtplib\n",
    "import os\n",
    "import json\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.utils import formatdate\n",
    "from os.path import join, dirname\n",
    "import time\n",
    "\n",
    "msg = MIMEMultipart()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ndjson\n",
    "from dotenv import load_dotenv\n",
    "import sentence_vectorizer\n",
    "import functools\n",
    "import demoji\n",
    "from ja_sentence_segmenter.common.pipeline import make_pipeline\n",
    "from ja_sentence_segmenter.concatenate.simple_concatenator import concatenate_matching\n",
    "from ja_sentence_segmenter.normalize.neologd_normalizer import normalize\n",
    "from ja_sentence_segmenter.split.simple_splitter import split_newline, split_punctuation\n",
    "\n",
    "import liking_users\n",
    "import liked_tweets\n",
    "import sentence_vectorizer\n",
    "\n",
    "# dotenv_path = join(dirname(__file__), '.env')\n",
    "# load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client():\n",
    "\n",
    "    DIR = 'data/mail_body.txt'\n",
    "\n",
    "    def __init__(self, client_data):\n",
    "\n",
    "        self.client_data = client_data\n",
    "        self.execution_time = 0\n",
    "        self.target_user = []\n",
    "        self.liked_tweet = []\n",
    "        self.degree = []\n",
    "\n",
    "    def extract_data(self):\n",
    "        \"\"\"クライアントの辞書から値をそれぞれ抽出\n",
    "        \"\"\"\n",
    "        # 送信先を抽出    \n",
    "        self.mail_address = self.client_data['mail_address']\n",
    "        # 宛名を抽出\n",
    "        self.name = self.client_data['name']\n",
    "        # キーワードを抽出\n",
    "        self.keyword = self.client_data['keyword']\n",
    "        # ツイッターIDを抽出\n",
    "        self.target_tweet_id = self.client_data['twitter_id']\n",
    "        # ツイッター本文を抽出\n",
    "        df_tweets = pd.DataFrame(self.client_data['tweets'])\n",
    "        self.target_tweet = df_tweets.iloc[:,1][df_tweets.iloc[:,2]==self.target_tweet_id].values[0]\n",
    "\n",
    "    def send_email(self):\n",
    "        \"\"\"クライアント宛にメール送信\n",
    "        \"\"\"\n",
    "        send_address = os.environ.get('MAIL_ADDRESS')\n",
    "        password = os.environ.get('MAIL_PASSWORD')\n",
    "\n",
    "        with open(DIR, encoding = \"utf-8\") as f:\n",
    "            body_temp = f.read()\n",
    "\n",
    "        subject = 'Twitter分析結果'\n",
    "        from_address = send_address\n",
    "        to_address = self.mail_address\n",
    "\n",
    "        # SMTPサーバに接続\n",
    "        smtpobj = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "        smtpobj.starttls()\n",
    "        smtpobj.login(send_address, password)\n",
    "\n",
    "        # メール作成\n",
    "        msg = MIMEMultipart()\n",
    "        msg['Subject'] = subject\n",
    "        msg['From'] = from_address\n",
    "        msg['To'] = to_address\n",
    "        msg['Date'] = formatdate()\n",
    "\n",
    "        # メール本文\n",
    "        # 一番大きい類似度のインデックス\n",
    "        max_idx = self.degree.index(max(self.degree))\n",
    "        \n",
    "        body_text = body_temp.format(name=self.name,\\\n",
    "            keyword=self.keyword, target_tweet=self.target_tweet,\\\n",
    "            target_user=self.target_user[max_idx], liked_tweet=self.liked_tweet[max_idx],\\\n",
    "            degree=max(self.degree), execution_time=self.execution_time)\n",
    "        body = MIMEText(body_text)\n",
    "        msg.attach(body)\n",
    "\n",
    "        # 作成したメールを送信\n",
    "        smtpobj.send_message(msg)\n",
    "        smtpobj.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Request returned an error: 403 {\"client_id\":\"22371308\",\"detail\":\"When authenticating requests to the Twitter API v2 endpoints, you must use keys and tokens from a Twitter developer App that is attached to a Project. You can create a project via the developer portal.\",\"registration_url\":\"https://developer.twitter.com/en/docs/projects/overview\",\"title\":\"Client Forbidden\",\"required_enrollment\":\"Standard Basic\",\"reason\":\"client-not-enrolled\",\"type\":\"https://api.twitter.com/2/problems/client-forbidden\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-304607267cb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-304607267cb5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(dir)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mdf_target_segments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize_target_segments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_target_segments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mdf_users\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_liking_users\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_tweet_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mdf_liked_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_liking_users_liked_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_tweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mcandidate_users\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_liked_tweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-e74fe83e2e31>\u001b[0m in \u001b[0;36mget_liking_users\u001b[0;34m(target_tweet_id)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \"\"\"\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# ターゲットツイートIDからいいねしたユーザーを検索\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mjson_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mliking_users\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_users\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_tweet_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# いいねしたユーザー情報のデータフレーム\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Aidemy/reserch_target_twitter/liking_users.py\u001b[0m in \u001b[0;36mget_users\u001b[0;34m(target_id)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_users\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet_fields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mjson_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnect_to_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Aidemy/reserch_target_twitter/liking_users.py\u001b[0m in \u001b[0;36mconnect_to_endpoint\u001b[0;34m(url, user_fields)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         raise Exception(\n\u001b[0m\u001b[1;32m     47\u001b[0m             \"Request returned an error: {} {}\".format(\n\u001b[1;32m     48\u001b[0m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Request returned an error: 403 {\"client_id\":\"22371308\",\"detail\":\"When authenticating requests to the Twitter API v2 endpoints, you must use keys and tokens from a Twitter developer App that is attached to a Project. You can create a project via the developer portal.\",\"registration_url\":\"https://developer.twitter.com/en/docs/projects/overview\",\"title\":\"Client Forbidden\",\"required_enrollment\":\"Standard Basic\",\"reason\":\"client-not-enrolled\",\"type\":\"https://api.twitter.com/2/problems/client-forbidden\"}"
     ]
    }
   ],
   "source": [
    "DIR = 'data/db_tweets.ndjson'\n",
    "\n",
    "def main(dir):\n",
    "    \"\"\"メイン\n",
    "    \"\"\"\n",
    "    client_data_list = []\n",
    "\n",
    "    with open(dir, 'r+') as json_file:\n",
    "        # 現在DBにあるクライアント情報を取得\n",
    "        json_client_data = ndjson.load(json_file)\n",
    "        # DBの内容を空にする\n",
    "        # json_file.truncate(0) \n",
    "\n",
    "        for data in json_client_data:\n",
    "            # 開始時間\n",
    "            start_time = time.perf_counter()\n",
    "            # クライアントクラスの初期化\n",
    "            client = Client(data)\n",
    "            # クライアントデータ準備\n",
    "            client.extract_data()\n",
    "            \n",
    "            df_target_segments = segment_target_tweet(client.target_tweet)\n",
    "            df_target_segments = vectorize_target_segments(df_target_segments)\n",
    "\n",
    "            df_users = get_liking_users(client.target_tweet_id)\n",
    "            df_liked_tweets = get_liking_users_liked_tweets(df_users, client.target_tweet)\n",
    "            candidate_users = select_tweets(client.keyword, df_liked_tweets)\n",
    "            candidate_users_segments = segment_tweet(candidate_users)\n",
    "            df_candidate_users = vectorize_candidate_segments(candidate_users_segments)\n",
    "            #dic_degree, dic_index = calculate_cosine_similarity(df_target_segments, df_candidate_users)\n",
    "            derived_result(client, df_target_segments, df_candidate_users, df_users, df_liked_tweets)\n",
    "            \n",
    "            client.send_email()\n",
    "            # 終了時間\n",
    "            execution_time = time.perf_counter() - start_time\n",
    "            client.execution_time = execution_time\n",
    "\n",
    "    return client\n",
    "                 \n",
    "client = main(DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.75378513800388\n"
     ]
    }
   ],
   "source": [
    "print(client.execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#udemy'"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "類似度スコア：0.901680052280426\n",
      "\n",
      "#今日の積み上げ 11/9\n",
      "\n",
      "#udemy ウェブ開発入門完全攻略コース\n",
      "JavaScript入門　32%終了\n",
      "\n",
      "講座を変えて、4度目のJS挑戦\n",
      "\n",
      "昨日、自社システムのトップページを作りましたが\n",
      "このページがページで終わらず、機能を実装させて、必ず生産性として役立てます💪\n",
      "\n",
      "#駆け出しエンジニア #プログラミング初心者 https://t.co/Do7aQ2cn6Q\n"
     ]
    }
   ],
   "source": [
    "maxidx = client.degree.index(max(client.degree))\n",
    "print(f'類似度スコア：{max(client.degree)}')\n",
    "print()\n",
    "print(client.liked_tweet[maxidx]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for degree_lst, index_lst in zip(dic_degree.values(), dic_index.values()):\n",
    "        \n",
    "    client.degree.append(max(degree_lst))\n",
    "    max_idx = degree_lst.index(max(degree_lst))\n",
    "    target_user_id = df_candidate_users.iloc[max_idx].name\n",
    "    # ターゲットユーザー名\n",
    "    print(df_users['username'][df_users['id']==target_user_id].values)\n",
    "    client.target_user.append(df_users['username'][df_users['id']==target_user_id])\n",
    "    # ツイート断片を抽出\n",
    "    segment_index = index_lst[max_idx]\n",
    "    segment = df_candidate_users.loc[target_user_id,'text'][segment_index]\n",
    "    # ツイート断片を含むツイート本文を抽出\n",
    "    df_mask = df_liked_tweets[target_user_id].str.contains(segment)\n",
    "    target_row = df_mask.first_valid_index()\n",
    "    # print(target_row)\n",
    "    # print(df_liked_tweets[target_user_id].iloc[target_row])\n",
    "    client.liked_tweet.append(df_liked_tweets[target_user_id].iloc[target_row])\n",
    "\n",
    "    print(client.degree)\n",
    "    print(client.target_user)\n",
    "    print(client.liked_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_liking_users(target_tweet_id):\n",
    "    \"\"\"ターゲットツイートにいいねしたユーザー情報をデータフレームで返す\n",
    "    \"\"\"\n",
    "    # ターゲットツイートIDからいいねしたユーザーを検索\n",
    "    json_response = liking_users.get_users(target_tweet_id)\n",
    "    # いいねしたユーザー情報のデータフレーム\n",
    "    return pd.json_normalize(json_response['data'])\n",
    "\n",
    "def get_liking_users_liked_tweets(df_users, target_tweet):\n",
    "    \"\"\"ユーザーデータフレームからユーザーがいいねしたツイートのデータフレームを返す\n",
    "    \"\"\"    \n",
    "    # ユーザーIDからいいねしたツイートを検索\n",
    "    dic_liked_tweets = liked_tweets.get_liked_tweets(df_users['id'])\n",
    "    # ユーザーごとの辞書データを結合したマルチカラムデータフレームを作成\n",
    "    df_liked_tweets = pd.concat({k: pd.DataFrame(v['data']) for k, v in dic_liked_tweets.items()}, \\\n",
    "        axis=0).unstack(0).swaplevel(1,0, axis=1).sort_index(axis=1)\n",
    "    # ユーザーIDを抽出    \n",
    "    user_ids = df_liked_tweets.columns.get_level_values(0).unique()\n",
    "\n",
    "    tweets_text_list = []\n",
    "    for ids in user_ids:\n",
    "        user_texts = df_liked_tweets[ids]['text'].copy()\n",
    "        # いいねしたツイートにターゲットツイートが含まれていたらNANに置換する\n",
    "        user_texts.replace(target_tweet, np.nan, inplace=True)\n",
    "        tweets_text_list.append(user_texts)\n",
    "        # いいねしたツイートのデータフレーム\n",
    "    df_tweets_text = pd.DataFrame(tweets_text_list, index=user_ids)\n",
    "    return df_tweets_text.T     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ユーザーのいいねツイートへの前処理用\n",
    "\n",
    "def select_tweets(keyword, df_liked_tweets):\n",
    "    \"\"\"ツイートのデータフレームからキーワードを含む文章をもつユーザーシリーズを作成\n",
    "    \"\"\"  \n",
    "    for col in df_liked_tweets.columns:\n",
    "        flag = df_liked_tweets[col].str.contains(keyword, na=False)\n",
    "        df_liked_tweets.loc[~flag, col] = np.nan\n",
    "\n",
    "    # NAN以外の値を持つユーザーIDを特定する（POSTする候補）\n",
    "    exist_flag = df_liked_tweets.count() != 0\n",
    "    user_name = df_liked_tweets.T[exist_flag].index\n",
    "\n",
    "    # POSTするユーザー候補ごとに関連ツイート文を全て結合\n",
    "    candidate_users = df_liked_tweets[user_name].T\n",
    "    # 後で文を区切る区切りのためツイート文の文末に'。'を追加\n",
    "    candidate_users += '。'\n",
    "    # ツイート文を結合\n",
    "    return candidate_users.iloc[:,0].str.cat([candidate_users.iloc[:,col] for col in candidate_users.columns[1:]], na_rep='')\n",
    "\n",
    "def segment_tweet(candidate_users):\n",
    "    \"\"\"ツイートを文単位でセパレートしたユーザーシリーズを返す\n",
    "    \"\"\"  \n",
    "    split_punc2 = functools.partial(split_punctuation, punctuations=r\"。!?\")\n",
    "    concat_tail_no = functools.partial(concatenate_matching, former_matching_rule=r\"^(?P<result>.+)(の)$\", remove_former_matched=False)\n",
    "    segmenter = make_pipeline(normalize, split_newline, concat_tail_no, split_punc2)\n",
    "\n",
    "    sentence_list = []\n",
    "    for text in candidate_users:\n",
    "        sentence_list.append(list(segmenter(text)))\n",
    "\n",
    "    candidate_users_segments = pd.Series(sentence_list, index=candidate_users.index, name='text')\n",
    "\n",
    "    for i in range(len(candidate_users_segments)):\n",
    "        candidate_users_segments[i] = [demoji.replace(string=seg, repl='') for seg in candidate_users_segments[i] if '。' != seg]\n",
    "\n",
    "    return candidate_users_segments\n",
    "\n",
    "def vectorize_candidate_segments(candidate_users_segments):\n",
    "    \"\"\"ユーザーシリーズに文単位のベクトルを追加したデータフレームを返す\n",
    "    \"\"\"  \n",
    "    # ベクトル表現を生成する\n",
    "    BSV = sentence_vectorizer.BertSequenceVectorizer()\n",
    "    vectors_list = [pd.Series(text).map(lambda x: BSV.vectorize(x)) for text in candidate_users_segments]\n",
    "    sr_vectors = pd.Series(vectors_list, index=candidate_users_segments.index, name='vector')\n",
    "    return pd.concat([candidate_users_segments, sr_vectors], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ターゲットツイートへの前処理\n",
    "\n",
    "def segment_target_tweet(target_tweet):\n",
    "    \"\"\"ターゲットツイートを文単位でセパレートしたデータフレームを返す\n",
    "    \"\"\"  \n",
    "    split_punc2 = functools.partial(split_punctuation, punctuations=r\"。!?\")\n",
    "    concat_tail_no = functools.partial(concatenate_matching, former_matching_rule=r\"^(?P<result>.+)(の)$\", remove_former_matched=False)\n",
    "    segmenter = make_pipeline(normalize, split_newline, concat_tail_no, split_punc2)\n",
    "\n",
    "    return pd.DataFrame(segmenter(target_tweet), columns=['text'])\n",
    "\n",
    "def vectorize_target_segments(df_target_segments):\n",
    "    \"\"\"文単位のターゲットツイートデータフレームにベクトルを追加\n",
    "    \"\"\"  \n",
    "    BSV = sentence_vectorizer.BertSequenceVectorizer()\n",
    "    df_target_segments['vector'] = df_target_segments['text'].map(lambda x: BSV.vectorize(x))\n",
    "    return df_target_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(df_target_segments, df_candidate_users):\n",
    "    \"\"\"ターゲットツイートとターゲットユーザーツイートの類似度を計算\n",
    "    \"\"\"     \n",
    "\n",
    "    # コサイン類似度の高いユーザーを算出\n",
    "    dic_degree = {}\n",
    "    dic_index = {}\n",
    "\n",
    "    for vec in df_candidate_users['vector']:\n",
    "\n",
    "        join = df_target_segments['vector'].append(vec)\n",
    "        for idx in range(len(df_target_segments)):\n",
    "            # ターゲットツイートセグメントのインデックスを選択するマスク\n",
    "            mask = np.ones(len(join), dtype=bool)\n",
    "            mask[:len(df_target_segments)+1] = False\n",
    "            mask[idx] = True\n",
    "            # 類似度行列\n",
    "            matrix = sentence_vectorizer.cos_sim_matrix(np.stack(join[mask]))\n",
    "            #print(np.sort(matrix[0])[::-1])\n",
    "            # ユーザーごとに最大の類似度とそのターゲットユーザーツイートのセグメントインデックスを取得\n",
    "            degree = np.sort(matrix[0])[::-1][1]\n",
    "            index = np.argsort(matrix[0])[::-1][1]\n",
    "\n",
    "            dic_degree.setdefault(idx, []).append(degree)\n",
    "            dic_index.setdefault(idx, []).append(index)\n",
    "\n",
    "    return dic_degree, dic_index\n",
    "\n",
    "def derived_result(client, df_target_segments, df_candidate_users, df_users, df_liked_tweets):\n",
    "    \"\"\"メール送信するユーザー名、ユーザーがいいねした関連度の高いツイート、関連スコア（0〜1）を返す\n",
    "    \"\"\"\n",
    "    dic_degree, dic_index = calculate_cosine_similarity(df_target_segments, df_candidate_users)\n",
    "    for degree_lst, index_lst in zip(dic_degree.values(), dic_index.values()):\n",
    "        # 最大の関連度スコア\n",
    "        client.degree.append(max(degree_lst))\n",
    "        max_idx = degree_lst.index(max(degree_lst))\n",
    "        target_user_id = df_candidate_users.iloc[max_idx].name\n",
    "        # ターゲットユーザー名\n",
    "        client.target_user.append(df_users['username'][df_users['id']==target_user_id].values)\n",
    "        segment_index = index_lst[max_idx]\n",
    "        # ツイート断片を抽出\n",
    "        segment = df_candidate_users.loc[target_user_id,'text'][segment_index]\n",
    "        # ツイート断片を含むツイート本文を抽出\n",
    "        df_mask = df_liked_tweets[target_user_id].str.contains(segment)\n",
    "        target_row = df_mask.first_valid_index()\n",
    "        client.liked_tweet.append(df_liked_tweets.loc[target_row, target_user_id])\n",
    "\n",
    "    print(client.degree, client.target_user, client.liked_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.target_user = []\n",
    "        self.liked_tweet = []\n",
    "        self.degree = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1175285742001475586</th>\n",
       "      <th>1260973997845393408</th>\n",
       "      <th>1279267537629278211</th>\n",
       "      <th>1282640602396364802</th>\n",
       "      <th>1290624958603829248</th>\n",
       "      <th>1297906406155104256</th>\n",
       "      <th>1356973982</th>\n",
       "      <th>1414520142</th>\n",
       "      <th>1415640388241555461</th>\n",
       "      <th>1449028461310332936</th>\n",
       "      <th>963753537053143042</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>まだ新規申し込みは停止中。\\n再会時には情報共有します。\\n\\n#駆け出しエンジニアと繋がり...</td>\n",
       "      <td>「マッチングアプリ」合格できました！ https://t.co/13jNVhiZmp #Re...</td>\n",
       "      <td>AR/VRには大きなポテンシャルがあると思いますが、Oculus Questに特化したコンテ...</td>\n",
       "      <td>私と迫さん（@yuki_99_s）のYouTube裏ノウハウBrainですが、3カ月以上経っ...</td>\n",
       "      <td>2021/11/08 8日目 作業時間:1h30m\\n\\nレスポンシブDog3まで完成！\\n...</td>\n",
       "      <td>【#tomoya_yoshimoto_in_isub #isub】from slack\\n快...</td>\n",
       "      <td>逆運動学に悩む・・・\\nhttps://t.co/U1vksBjNQi\\n\\n#Arduin...</td>\n",
       "      <td>離職率の高い会社ってすごいチャンスだったりする。\\n\\n先輩や上司がどんどん辞めていくので、...</td>\n",
       "      <td>#今日の積み上げ\\n今日はエナジードリンクの缶を積みました‼️ フリーランスとして独立してい...</td>\n",
       "      <td>昨日今日と停電&amp;amp;ネット絶不調でプログラミング学習はおろか、SNSさえまともにできない...</td>\n",
       "      <td>Rails　Modelで整数値に限定したけば\\nvalidates :user_id, nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@banburero001 嘘というか、商材屋が人を騙すためのエサですね。\\n月収○桁！！と...</td>\n",
       "      <td>服装に自信がない #プログラマー 必見！\\n#エンジニア 向けブランド！\\n\\n#プログラミ...</td>\n",
       "      <td>#ギークハウス 品川・五反田・大崎では住人を募集中!\\n\\nコンセプトはエンジニア同士(志望...</td>\n",
       "      <td>おはようございます☀️\\n\\n「誰でもできること」を「誰もできないくらい続ける」が成功のコツ...</td>\n",
       "      <td>#デイトラ\\n分からないところガンガン呟いていきます😵‍💫\\n\\n中級編でレスポンシブの\\n...</td>\n",
       "      <td>自分はみんなを助けたいと言っても、結局誰も人が助けを求めて来ないのならそれはまずその人に人を...</td>\n",
       "      <td>頭悪い奴は #ゲーム だろうが攻略法見てりゃ良い\\n\\n#プログラミング など専門知識にして...</td>\n",
       "      <td>持つべきは絶対的な危機感\\n会社員時代には終身雇用で安泰と思わないこと。常に疑問符をもち10...</td>\n",
       "      <td>[From ﾕﾃﾞﾀﾏｸﾞｫbot]\\n🐣 #今日の積み上げ\\n#駆け出しエンジニアと繋がり...</td>\n",
       "      <td>Progateでプログラミング勉強始めました！！\\nHTML＆CSS　初級編やってます！\\n...</td>\n",
       "      <td>🙇🏻‍♂️御礼🙇🏻‍♂️\\n\\nクラウドワークスで何度応募してもダメな人のためのBrain（...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>かごもく #50 認証デバイス特集 (FIDO2 とか Yubikey とか) / http...</td>\n",
       "      <td>N予備校のプログラミング入門コースはゴールが『Webエンジニアとして内定もらって働ける』レベ...</td>\n",
       "      <td>【2021年最新版】\\n 国内最大手のプログラミングスクール\\n侍エンジニア塾の気になる料金...</td>\n",
       "      <td>色々と記事にして共有していきたい知識がここ1年でたくさん身についた気がします！\\n\\nいま行...</td>\n",
       "      <td>実戦した中にかなり効果的な勉強は\\nゴールから始める事です！\\n資格なら過去問から解く\\n制...</td>\n",
       "      <td>トリニタスお仕事情報♪高額案件あり♪スキルアップ♪選べる案件♪　https://t.co/t...</td>\n",
       "      <td>2021-11-08 17:00:02\\n仙台市\\n現在の天候：所により曇り\\n　　　気温：...</td>\n",
       "      <td>#Qiita 投稿しました。\\n\\nhttps://t.co/cTLwZgbcWY\\n\\n#...</td>\n",
       "      <td>ブン・レモングラス チキン『ベトニャット』新宿御苑 #おは戦31102nk #おつかれ戦隊1...</td>\n",
       "      <td>PHPの質問にまだ答えられなくて悲しい💦\\n知り合いでPHPのエンジニアさんとかいればよかっ...</td>\n",
       "      <td>／\\n🔰未経験者必見！\\n＼\\n\\n未経験からのIT転職は20代が有利！🚀\\n転職するために...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 1175285742001475586  \\\n",
       "0  まだ新規申し込みは停止中。\\n再会時には情報共有します。\\n\\n#駆け出しエンジニアと繋がり...   \n",
       "1  @banburero001 嘘というか、商材屋が人を騙すためのエサですね。\\n月収○桁！！と...   \n",
       "2  かごもく #50 認証デバイス特集 (FIDO2 とか Yubikey とか) / http...   \n",
       "\n",
       "                                 1260973997845393408  \\\n",
       "0  「マッチングアプリ」合格できました！ https://t.co/13jNVhiZmp #Re...   \n",
       "1  服装に自信がない #プログラマー 必見！\\n#エンジニア 向けブランド！\\n\\n#プログラミ...   \n",
       "2  N予備校のプログラミング入門コースはゴールが『Webエンジニアとして内定もらって働ける』レベ...   \n",
       "\n",
       "                                 1279267537629278211  \\\n",
       "0  AR/VRには大きなポテンシャルがあると思いますが、Oculus Questに特化したコンテ...   \n",
       "1  #ギークハウス 品川・五反田・大崎では住人を募集中!\\n\\nコンセプトはエンジニア同士(志望...   \n",
       "2  【2021年最新版】\\n 国内最大手のプログラミングスクール\\n侍エンジニア塾の気になる料金...   \n",
       "\n",
       "                                 1282640602396364802  \\\n",
       "0  私と迫さん（@yuki_99_s）のYouTube裏ノウハウBrainですが、3カ月以上経っ...   \n",
       "1  おはようございます☀️\\n\\n「誰でもできること」を「誰もできないくらい続ける」が成功のコツ...   \n",
       "2  色々と記事にして共有していきたい知識がここ1年でたくさん身についた気がします！\\n\\nいま行...   \n",
       "\n",
       "                                 1290624958603829248  \\\n",
       "0  2021/11/08 8日目 作業時間:1h30m\\n\\nレスポンシブDog3まで完成！\\n...   \n",
       "1  #デイトラ\\n分からないところガンガン呟いていきます😵‍💫\\n\\n中級編でレスポンシブの\\n...   \n",
       "2  実戦した中にかなり効果的な勉強は\\nゴールから始める事です！\\n資格なら過去問から解く\\n制...   \n",
       "\n",
       "                                 1297906406155104256  \\\n",
       "0  【#tomoya_yoshimoto_in_isub #isub】from slack\\n快...   \n",
       "1  自分はみんなを助けたいと言っても、結局誰も人が助けを求めて来ないのならそれはまずその人に人を...   \n",
       "2  トリニタスお仕事情報♪高額案件あり♪スキルアップ♪選べる案件♪　https://t.co/t...   \n",
       "\n",
       "                                          1356973982  \\\n",
       "0  逆運動学に悩む・・・\\nhttps://t.co/U1vksBjNQi\\n\\n#Arduin...   \n",
       "1  頭悪い奴は #ゲーム だろうが攻略法見てりゃ良い\\n\\n#プログラミング など専門知識にして...   \n",
       "2  2021-11-08 17:00:02\\n仙台市\\n現在の天候：所により曇り\\n　　　気温：...   \n",
       "\n",
       "                                          1414520142  \\\n",
       "0  離職率の高い会社ってすごいチャンスだったりする。\\n\\n先輩や上司がどんどん辞めていくので、...   \n",
       "1  持つべきは絶対的な危機感\\n会社員時代には終身雇用で安泰と思わないこと。常に疑問符をもち10...   \n",
       "2  #Qiita 投稿しました。\\n\\nhttps://t.co/cTLwZgbcWY\\n\\n#...   \n",
       "\n",
       "                                 1415640388241555461  \\\n",
       "0  #今日の積み上げ\\n今日はエナジードリンクの缶を積みました‼️ フリーランスとして独立してい...   \n",
       "1  [From ﾕﾃﾞﾀﾏｸﾞｫbot]\\n🐣 #今日の積み上げ\\n#駆け出しエンジニアと繋がり...   \n",
       "2  ブン・レモングラス チキン『ベトニャット』新宿御苑 #おは戦31102nk #おつかれ戦隊1...   \n",
       "\n",
       "                                 1449028461310332936  \\\n",
       "0  昨日今日と停電&amp;ネット絶不調でプログラミング学習はおろか、SNSさえまともにできない...   \n",
       "1  Progateでプログラミング勉強始めました！！\\nHTML＆CSS　初級編やってます！\\n...   \n",
       "2  PHPの質問にまだ答えられなくて悲しい💦\\n知り合いでPHPのエンジニアさんとかいればよかっ...   \n",
       "\n",
       "                                  963753537053143042  \n",
       "0  Rails　Modelで整数値に限定したけば\\nvalidates :user_id, nu...  \n",
       "1  🙇🏻‍♂️御礼🙇🏻‍♂️\\n\\nクラウドワークスで何度応募してもダメな人のためのBrain（...  \n",
       "2  ／\\n🔰未経験者必見！\\n＼\\n\\n未経験からのIT転職は20代が有利！🚀\\n転職するために...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# このセルのdf_liked_tweets変数の中身はキャッシュで残ってるもの\n",
    "# リスタートしたら消える\n",
    "\n",
    "user_ids = df_liked_tweets.columns.get_level_values(0).unique()\n",
    "\n",
    "tweets_text_list = []\n",
    "for ids in user_ids:\n",
    "    user_texts = df_liked_tweets[ids]['text'].copy()\n",
    "    # いいねしたツイートにターゲットツイートが含まれていたらNANに置換する\n",
    "    user_texts.replace(twlist[1], np.nan, inplace=True)\n",
    "    tweets_text_list.append(user_texts)\n",
    "    # いいねしたツイートのデータフレーム\n",
    "df_tweets_text = pd.DataFrame(tweets_text_list, index=user_ids).T\n",
    "df_tweets_text.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ターゲットキーワードを含むツイート文以外はNANに置換する\n",
    "keyword = '#GoogleAppsScript'\n",
    "for col in df_tweets_text.columns:\n",
    "    flag = df_tweets_text[col].str.contains(keyword, na=False)\n",
    "    df_tweets_text.loc[~flag, col] = np.nan\n",
    "\n",
    "# NAN以外の値を持つユーザーIDを特定する（POSTする候補）\n",
    "exist_flag = df_tweets_text.count() != 0\n",
    "user_name = df_tweets_text.T[exist_flag].index\n",
    "\n",
    "# POSTするユーザー候補ごとに関連ツイート文を全て結合\n",
    "candidate_users = df_tweets_text[user_name].T\n",
    "# 後で文を区切る区切りのためツイート文の文末に'。'を追加\n",
    "candidate_users += '。'\n",
    "# ツイート文を結合\n",
    "candidate_users['all'] = candidate_users.iloc[:,0].str.cat([candidate_users.iloc[:,col] for col in candidate_users.columns[1:]], na_rep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1282640602396364802    2つとも使えるようになりたい🤔🤔ww\\n\\n#使いたい構文 #JavaScript #Goo...\n",
       "1356973982             二次元配列から特定の列だけ取り出す方法\\n\\nこれめちゃ便利🤔🤔\\n\\nconst pick...\n",
       "Name: all, dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can_user = candidate_users['all']\n",
    "can_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_punc2 = functools.partial(split_punctuation, punctuations=r\"。!?\")\n",
    "concat_tail_no = functools.partial(concatenate_matching, former_matching_rule=r\"^(?P<result>.+)(の)$\", remove_former_matched=False)\n",
    "segmenter = make_pipeline(normalize, split_newline, concat_tail_no, split_punc2)\n",
    "\n",
    "# 結合したツイート文を文単位で分割する\n",
    "sentence_list = []\n",
    "for text in can_user:\n",
    "    sentence_list.append(list(segmenter(text)))\n",
    "\n",
    "#can_user['text'] = df_list\n",
    "can_user_sentence = pd.Series(sentence_list, index=can_user.index, name='text')\n",
    "\n",
    "# '。'だけの文字と絵文字を削除\n",
    "\n",
    "for i in range(len(can_user_sentence)):\n",
    "    can_user_sentence[i] = [demoji.replace(string=seg, repl='') for seg in can_user_sentence[i] if '。' != seg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2つとも使えるようになりたいww',\n",
       " '#使いたい構文#JavaScript#GoogleAppsScript ',\n",
       " '#filter#配列',\n",
       " '#プログラミング#プログラミング初心者と繋がりたい#駆け出しエンジニアと繋がりたい#駆け出しエンジニアhttps://t.co/Ne6kOA0MVw。']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can_user_sentence[0][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2つとも使えるようになりたい🤔🤔ww',\n",
       " '#使いたい構文#JavaScript#GoogleAppsScript ',\n",
       " '#filter#配列',\n",
       " '#プログラミング#プログラミング初心者と繋がりたい#駆け出しエンジニアと繋がりたい#駆け出しエンジニアhttps://t.co/Ne6kOA0MVw。']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can_user_sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1282640602396364802</th>\n",
       "      <td>[2つとも使えるようになりたいww, #使いたい構文#JavaScript#GoogleAp...</td>\n",
       "      <td>0    [-0.18843903, -0.19478449, -0.020317644, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356973982</th>\n",
       "      <td>[二次元配列から特定の列だけ取り出す方法, これめちゃ便利, const picked＝ht...</td>\n",
       "      <td>0    [-0.14769673, -0.20070626, -0.4178725, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "1282640602396364802  [2つとも使えるようになりたいww, #使いたい構文#JavaScript#GoogleAp...   \n",
       "1356973982           [二次元配列から特定の列だけ取り出す方法, これめちゃ便利, const picked＝ht...   \n",
       "\n",
       "                                                                vector  \n",
       "1282640602396364802  0    [-0.18843903, -0.19478449, -0.020317644, ...  \n",
       "1356973982           0    [-0.14769673, -0.20070626, -0.4178725, -0...  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_candidate_segments(can_user_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d2d66490f4cee6a5e888806b9e6f453dddbe2283d64397fcec40d4118eb281a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('streamlit-custom': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
